{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMuIlzSMTB5Q2aCSrMVaB9F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/farzadgolnoori/test/blob/main/SignalProcessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mount Drive You can use blew command if you use local computer not colab\n",
        "DIR = os.path.abspath('./dataset')"
      ],
      "metadata": {
        "id": "UBPX6R4S6Q5Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StR9CxL36Uhp",
        "outputId": "926a5057-6af5-43cd-c9e6-295735e65c5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get data, labels and create dataset\n",
        " "
      ],
      "metadata": {
        "id": "acZlb_Jg6u-C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RpkSdLyvByom",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3423c8b1-789c-4b08-d22c-94ac26f5a18b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 5720 examples for label Cars encoded with 0\n",
            "Loaded 5065 examples for label Drones encoded with 1\n",
            "Loaded 6700 examples for label People encoded with 2\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "DIR = os.path.abspath('/content/drive/My Drive/RadarProject/fulldataset')\n",
        "\n",
        "LABEL_MAPPER = {'Cars': 0, 'Drones': 1, 'People': 2}\n",
        "\n",
        "INV_LABEL_MAPPER = {v: k for k, v in LABEL_MAPPER.items()}\n",
        "\n",
        "#DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "def get_data_for_label(label: str):\n",
        "    X, y = [], []\n",
        "    for root, dirs, files in os.walk(os.path.join(DIR, label)):\n",
        "        for file in files:\n",
        "            if file.endswith('.csv'):\n",
        "                y.append(LABEL_MAPPER[label])\n",
        "                df = pd.read_csv(os.path.join(root, file), sep=',', header=None)\n",
        "                X.append(df.values)\n",
        "    print(f'Loaded {len(y)} examples for label {label} encoded with {LABEL_MAPPER[label]}')\n",
        "    return X, y\n",
        "\n",
        "X_cars, y_cars = get_data_for_label('Cars')\n",
        "X_drones, y_drones = get_data_for_label('Drones')\n",
        "X_people, y_people = get_data_for_label('People')\n",
        "\n",
        "X = X_cars + X_drones + X_people\n",
        "y = y_cars + y_drones + y_people\n",
        "X, y = np.array(X), np.array(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Changing image size to 100*100 for transfer learning(to using pre-trained models your images should be 32*32 size)\n",
        "\n",
        "# **Do Not use this section if you don't use transfer learning**"
      ],
      "metadata": {
        "id": "QqwNQVYky4Ek"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "plt.show()\n",
        "Xresized=[]\n",
        "for pic in X:\n",
        "  resizedImage=np.array(Image.fromarray(pic).resize((100, 100))).astype('float32')\n",
        "  Xresized.append(resizedImage)\n",
        "Xresized\n",
        "print('finished')\n",
        "Xresized=np.array(Xresized)\n",
        "Xresized.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIuHpX1ok6OV",
        "outputId": "5aa04f74-87de-4c80-c92e-8e16683cefac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "finished\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17485, 100, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Changing image channel from 1 to 3 (pre-trained models accept just RGB images because they trained on imagenet dataset.\n",
        "\n",
        "# **Do Not use this section if you don't use transfer learning**"
      ],
      "metadata": {
        "id": "RmCoFran1CHw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Xresized=np.repeat(Xresized[..., np.newaxis], 3, -1)\n",
        "print(Xresized.shape)  # "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbv_EWH_-lAx",
        "outputId": "7510eae2-bd1a-494d-f692-cac796cfcd5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(17485, 100, 100, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Showing **imges** 11 61 (orginal) and 100 100 in a row"
      ],
      "metadata": {
        "id": "lqWo7j7VzfqI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from PIL import Image\n",
        "resizedImage=np.array(Image.fromarray(X[0]).resize((100, 100))).astype('float32')\n",
        "fig, axs =plt.subplots(2, 2, figsize=(10, 10))\n",
        "axs[0, 0].imshow(X[0], cmap='jet', vmin=-140, vmax=-70)\n",
        "axs[0, 1].imshow(resizedImage, cmap='jet', vmin=-140, vmax=-70)"
      ],
      "metadata": {
        "id": "VJyVYQQ9msYH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dividing Dataset to train, test and validation subsets\n",
        "\n",
        "**If you don't use transfer learning instead of Xresized use X array.**"
      ],
      "metadata": {
        "id": "jY8DB8SZqD8l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "SEED = 0\n",
        "val_size, test_size = 0.1, 0.1\n",
        "\n",
        "# train-test split\n",
        "X_trainval, X_test, y_trainval, y_test = train_test_split(\n",
        "    Xresized, y, test_size=test_size, random_state=SEED, stratify=y\n",
        ")\n",
        "\n",
        "# train-validation split\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_trainval,\n",
        "    y_trainval,\n",
        "    test_size=val_size / (1 - test_size),\n",
        "    random_state=SEED,\n",
        "    stratify=y_trainval,\n",
        ")\n",
        "\n",
        "print(X_train.shape)\n",
        "\n",
        "print(X_val.shape)\n",
        "\n",
        "print(X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILa0fiGFqC7a",
        "outputId": "08a851cf-c3b9-473c-bb25-7d72e2f5ac8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(13987, 100, 100, 3)\n",
            "(1749, 100, 100, 3)\n",
            "(1749, 100, 100, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First Custom Model(from scratch without using transfer learning)"
      ],
      "metadata": {
        "id": "WT4rlBuS2eZi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.optimizers import Adam\n",
        "\n",
        "from tensorflow.keras.optimizers import Adadelta,Adagrad,SGD,RMSprop,Adam,SGD\n",
        "\n",
        "from tensorflow.keras.layers import SeparableConv2D,Conv2D,MaxPooling2D,Flatten\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D,Dropout,Input\n",
        "from tensorflow.keras.models import Sequential,Model\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "\n",
        "# Conv Layer 1\n",
        "model.add(Conv2D(filters = 10, kernel_size=(3, 3), activation='relu',input_shape= (100,100,3)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(filters = 20, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(64, activation='relu'))\n",
        "\n",
        "model.add(Dense(64, activation='relu'))\n",
        "\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "model.compile(loss = 'sparse_categorical_crossentropy',optimizer='adam', metrics = ['accuracy'])\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "#adam_opt=Adam(lr=0.0001, beta_1=0.6, beta_2=0.995, epsilon=None, decay=0.0, amsgrad=False)\n",
        "\n",
        "#model.compile(loss = 'categorical_crossentropy',optimizer=adam_opt, metrics = ['accuracy'])\n",
        "\n",
        "model.fit(X_train, y_train, epochs=50, batch_size=32,validation_data=(X_val, y_val), verbose=1, shuffle=True)\n"
      ],
      "metadata": {
        "id": "HLvVjcvzBAtx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transfer Learning _ Feature Extractor( mobile-netV2, VGG16, ResNet50, DenseNet201, Xception)"
      ],
      "metadata": {
        "id": "VbI2jLmIE5FH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import VGG16 \n",
        "from tensorflow.keras.applications import DenseNet201\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.applications import MobileNet\n",
        "from tensorflow.keras.layers import SeparableConv2D,Conv2D,MaxPooling2D,Flatten\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D,Dropout,Input\n",
        "from tensorflow.keras.models import Sequential,Model\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.applications import EfficientNetB4\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "base_model = DenseNet201(weights='imagenet',include_top= False,input_shape=(100,100,3))\n",
        "\n",
        "x = base_model.output\n",
        "\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "x = Dense(64, activation='relu')(x)\n",
        "\n",
        "predictions = Dense(3, activation= 'softmax')(x)\n",
        "\n",
        "model = Model(base_model.input,predictions)\n",
        "\n",
        "optimizer = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=True)\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy',optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, y_train, epochs=30, batch_size=32,validation_data=(X_val,y_val), verbose=1)\n",
        "\n",
        "scores= model.evaluate(X_test, y_test)\n",
        "    \n",
        "print(scores[1])\n"
      ],
      "metadata": {
        "id": "USzTAGV7ItVA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import VGG16 \n",
        "from tensorflow.keras.applications import DenseNet201\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.applications import MobileNet\n",
        "from tensorflow.keras.layers import SeparableConv2D,Conv2D,MaxPooling2D,Flatten\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D,Dropout,Input\n",
        "from tensorflow.keras.models import Sequential,Model\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.applications import EfficientNetB4\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "base_model = ResNet50(weights='imagenet',include_top= False,input_shape=(100,100,3))\n",
        "\n",
        "x = base_model.output\n",
        "\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "x = Dense(64, activation='relu')(x)\n",
        "\n",
        "predictions = Dense(3, activation= 'softmax')(x)\n",
        "\n",
        "model = Model(base_model.input,predictions)\n",
        "\n",
        "optimizer = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=True)\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy',optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, y_train, epochs=30, batch_size=32,validation_data=(X_val,y_val), verbose=1)\n",
        "\n",
        "scores= model.evaluate(X_test, y_test)\n",
        "    \n",
        "print(scores[1])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Zm_Ayh1FA9I",
        "outputId": "286c628e-0e57-4b9f-a4c0-0fedbc3fc269"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 2s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores= model.evaluate(X_test, y_test)\n",
        "    \n",
        "print(scores[1])"
      ],
      "metadata": {
        "id": "NHxFESXzfVKW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    \n",
        "model.save(\"/content/drive/My Drive/app/\"+\"signal_densenet\"+'.h5')"
      ],
      "metadata": {
        "id": "qGAujsO73czt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}